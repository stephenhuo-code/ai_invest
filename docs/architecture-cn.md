# AI æŠ•èµ„è¶‹åŠ¿ - ç³»ç»Ÿæ¶æ„æ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
2. [æ¶æ„æ¼”è¿›](#æ¶æ„æ¼”è¿›)
3. [åˆ†å±‚æ¶æ„è®¾è®¡](#åˆ†å±‚æ¶æ„è®¾è®¡)
4. [æ•°æ®æ¨¡å‹](#æ•°æ®æ¨¡å‹)
5. [æ ¸å¿ƒæ¶æ„æ¨¡å¼](#æ ¸å¿ƒæ¶æ„æ¨¡å¼)
6. [æŠ€æœ¯æ ˆ](#æŠ€æœ¯æ ˆ)
7. [æ¶æ„å†³ç­–è®°å½•](#æ¶æ„å†³ç­–è®°å½•)
8. [ç¬¬äºŒé˜¶æ®µå‡†å¤‡](#ç¬¬äºŒé˜¶æ®µå‡†å¤‡)

---

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

AI æŠ•èµ„è¶‹åŠ¿æ˜¯ä¸€ä¸ªæ™ºèƒ½æŠ•èµ„ç ”ç©¶è‡ªåŠ¨åŒ–å¹³å°ï¼Œé€šè¿‡AIé©±åŠ¨çš„åˆ†æå’Œå‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼Œå°†é‡‘èæ–°é—»å’Œå¸‚åœºæ•°æ®è½¬åŒ–ä¸ºå¯æ“ä½œçš„æŠ•èµ„æ´å¯Ÿã€‚

### æ ¸å¿ƒèƒ½åŠ›

- **ğŸ” æ™ºèƒ½æ–°é—»å¤„ç†**ï¼šè‡ªåŠ¨åŒ–æ–°é—»è·å–ã€å†…å®¹æå–å’Œå»é‡
- **ğŸ¤– AIé©±åŠ¨åˆ†æ**ï¼šä½¿ç”¨OpenAIæ¨¡å‹è¿›è¡Œå¤šç»´åº¦å†…å®¹åˆ†æï¼ˆæƒ…æ„Ÿåˆ†æã€ä¸»é¢˜æå–ã€è‚¡ç¥¨æåŠã€è¶‹åŠ¿åˆ†æï¼‰
- **ğŸ¯ å‘é‡ç›¸ä¼¼åº¦æœç´¢**ï¼šä½¿ç”¨PostgreSQL + pgvectorå®ç°é«˜æ€§èƒ½è¯­ä¹‰æœç´¢
- **ğŸ“Š æŠ•èµ„æŠ¥å‘Šç”Ÿæˆ**ï¼šè‡ªåŠ¨ç”ŸæˆåŒ…å«å¸‚åœºæ´å¯Ÿçš„æŠ•èµ„æŠ¥å‘Š
- **ğŸš€ å¯æ‰©å±•æ¶æ„**ï¼šåŸºäºé¢†åŸŸé©±åŠ¨è®¾è®¡ï¼Œä¸ºæ··åˆå‘é‡å­˜å‚¨åšå¥½å‡†å¤‡

### ä¸šåŠ¡ä»·å€¼

```mermaid
flowchart LR
    A[åŸå§‹é‡‘èæ–°é—»] --> B[AIå¤„ç†æµæ°´çº¿]
    B --> C[ç»“æ„åŒ–æ´å¯Ÿ]
    C --> D[æŠ•èµ„æŠ¥å‘Š]
    D --> E[äº¤æ˜“å†³ç­–]
    
    classDef input fill:#e1f5fe,stroke:#0277bd
    classDef process fill:#f3e5f5,stroke:#7b1fa2
    classDef output fill:#e8f5e8,stroke:#2e7d32
    
    class A input
    class B,C process
    class D,E output
```

---

## ğŸ—ï¸ æ¶æ„æ¼”è¿›

### ä»å•ä½“æ¶æ„åˆ°é¢†åŸŸé©±åŠ¨è®¾è®¡

ç³»ç»Ÿå·²ä»å•ä½“æ¶æ„æ¼”è¿›ä¸ºç°ä»£åŒ–çš„åˆ†å±‚DDDæ¶æ„ï¼Œä»¥æ”¯æŒå¯æ‰©å±•æ€§ã€å¯ç»´æŠ¤æ€§å’Œæœªæ¥å¢å¼ºã€‚

```mermaid
graph TB
    subgraph "ç¬¬0é˜¶æ®µï¼šå•ä½“æ¶æ„ï¼ˆé—ç•™ï¼‰"
        M1[å•ä¸€Pythonè„šæœ¬]
        M2[ç›´æ¥è°ƒç”¨OpenAI]
        M3[åŸºäºæ–‡ä»¶çš„å­˜å‚¨]
        M4[æ‰‹åŠ¨æŠ¥å‘Šç”Ÿæˆ]
    end
    
    subgraph "ç¬¬1é˜¶æ®µï¼šå½“å‰DDDæ¶æ„"
        P1[é¢†åŸŸå±‚]
        P2[åº”ç”¨å±‚]
        P3[åŸºç¡€è®¾æ–½å±‚]
        P4[è¡¨ç°å±‚]
        P5[PostgreSQL + pgvector]
        P6[å‘é‡å­˜å‚¨å·¥å‚]
    end
    
    subgraph "ç¬¬2é˜¶æ®µï¼šè§„åˆ’çš„æ··åˆæ¶æ„"
        F1[å¢å¼ºçš„é¢†åŸŸæ¨¡å‹]
        F2[CQRSå®ç°]
        F3[æ··åˆå‘é‡å­˜å‚¨]
        F4[äº‹ä»¶é©±åŠ¨æ¶æ„]
        F5[PostgreSQL + Qdrant]
    end
    
    M1 --> P1
    M2 --> P2
    M3 --> P3
    M4 --> P4
    
    P5 --> F5
    P6 --> F3
    
    classDef legacy fill:#ffebee,stroke:#c62828
    classDef current fill:#e8f5e8,stroke:#2e7d32
    classDef future fill:#e3f2fd,stroke:#1565c0
    
    class M1,M2,M3,M4 legacy
    class P1,P2,P3,P4,P5,P6 current
    class F1,F2,F3,F4,F5 future
```

### å…³é”®æ¶æ„æ”¹è¿›

| æ–¹é¢ | å•ä½“æ¶æ„ | å½“å‰DDD | æœªæ¥æ··åˆ |
|--------|------------|-------------|---------------|
| **å¯ç»´æŠ¤æ€§** | ä½ | é«˜ | éå¸¸é«˜ |
| **å¯æµ‹è¯•æ€§** | å›°éš¾ | å®¹æ˜“ | å…¨é¢ |
| **å¯æ‰©å±•æ€§** | æœ‰é™ | è‰¯å¥½ | ä¼˜ç§€ |
| **å‘é‡æœç´¢** | æ—  | PostgreSQL+pgvector | æ··åˆå­˜å‚¨ |
| **é¢†åŸŸé€»è¾‘** | åˆ†æ•£ | é›†ä¸­åŒ– | äº‹ä»¶é©±åŠ¨ |

---

## ğŸ›ï¸ åˆ†å±‚æ¶æ„è®¾è®¡

ç³»ç»Ÿéµå¾ªé¢†åŸŸé©±åŠ¨è®¾è®¡ï¼ˆDDDï¼‰åŸåˆ™ï¼Œåœ¨å››ä¸ªä¸åŒå±‚çº§ä¹‹é—´æ˜ç¡®åˆ†ç¦»å…³æ³¨ç‚¹ã€‚

```mermaid
graph TB
    subgraph "ğŸ¨ è¡¨ç°å±‚"
        P1[FastAPI REST API]
        P2[è¯·æ±‚/å“åº”æ¨¡å¼]
        P3[CORSä¸­é—´ä»¶]
        P4[è®¤è¯ä¸­é—´ä»¶]
    end
    
    subgraph "ğŸ’¼ åº”ç”¨å±‚"
        A1[ç”¨ä¾‹ / å·¥ä½œæµ]
        A2[åº”ç”¨æœåŠ¡]
        A3[æ•°æ®ä¼ è¾“å¯¹è±¡]
        A4[å‘½ä»¤/æŸ¥è¯¢å¤„ç†å™¨]
    end
    
    subgraph "ğŸ¢ é¢†åŸŸå±‚"
        D1[å®ä½“: NewsArticle, VectorDocument, AnalysisResult]
        D2[å€¼å¯¹è±¡: Sentiment, StockMention]
        D3[ä»“å‚¨æ¥å£]
        D4[é¢†åŸŸæœåŠ¡]
    end
    
    subgraph "âš¡ åŸºç¡€è®¾æ–½å±‚"
        I1[PostgreSQLæ•°æ®åº“]
        I2[å‘é‡å­˜å‚¨å·¥å‚]
        I3[å¤–éƒ¨æœåŠ¡: OpenAI, æ•°æ®æº]
        I4[é…ç½®ç®¡ç†]
    end
    
    P1 --> A1
    P2 --> A2
    A1 --> D1
    A2 --> D3
    D3 --> I1
    A1 --> I3
    
    classDef presentation fill:#e3f2fd,stroke:#1565c0
    classDef application fill:#f3e5f5,stroke:#7b1fa2
    classDef domain fill:#e8f5e8,stroke:#2e7d32
    classDef infrastructure fill:#fff3e0,stroke:#f57c00
    
    class P1,P2,P3,P4 presentation
    class A1,A2,A3,A4 application
    class D1,D2,D3,D4 domain
    class I1,I2,I3,I4 infrastructure
```

### ğŸ“ ç›®å½•ç»“æ„

```
src/
â”œâ”€â”€ domain/                 # ğŸ¢ é¢†åŸŸå±‚ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ entities/           # ä¸šåŠ¡å®ä½“
â”‚   â”œâ”€â”€ repositories/       # ä»“å‚¨æ¥å£
â”‚   â””â”€â”€ value_objects/      # ä¸å¯å˜å€¼å¯¹è±¡
â”œâ”€â”€ application/            # ğŸ’¼ åº”ç”¨å±‚ - ç”¨ä¾‹
â”‚   â”œâ”€â”€ use_cases/          # ä¸šåŠ¡å·¥ä½œæµ
â”‚   â”œâ”€â”€ services/           # åº”ç”¨æœåŠ¡
â”‚   â””â”€â”€ dtos/               # æ•°æ®ä¼ è¾“å¯¹è±¡
â”œâ”€â”€ infrastructure/         # âš¡ åŸºç¡€è®¾æ–½å±‚ - å¤–éƒ¨å…³æ³¨ç‚¹
â”‚   â”œâ”€â”€ database/           # PostgreSQL + SQLAlchemy
â”‚   â”œâ”€â”€ external/           # å¤–éƒ¨æœåŠ¡é›†æˆ
â”‚   â””â”€â”€ config/             # é…ç½®ç®¡ç†
â””â”€â”€ presentation/           # ğŸ¨ è¡¨ç°å±‚ - APIæ¥å£
    â”œâ”€â”€ api/                # FastAPIè·¯ç”±
    â”œâ”€â”€ schemas/            # è¯·æ±‚/å“åº”æ¨¡å‹
    â””â”€â”€ middleware/         # æ¨ªåˆ‡å…³æ³¨ç‚¹
```

### å±‚çº§èŒè´£

#### ğŸ¢ é¢†åŸŸå±‚ (`src/domain/`)
**ç›®çš„**ï¼šåŒ…å«ä¸ä¾èµ–å¤–éƒ¨ç³»ç»Ÿçš„çº¯ä¸šåŠ¡é€»è¾‘

**ç»„ä»¶**:
- **å®ä½“** (`entities/`)ï¼šå…·æœ‰èº«ä»½å’Œç”Ÿå‘½å‘¨æœŸçš„æ ¸å¿ƒä¸šåŠ¡å¯¹è±¡
  - `NewsArticle`ï¼šè¡¨ç¤ºå…·æœ‰å¤„ç†çŠ¶æ€çš„é‡‘èæ–°é—»
  - `VectorDocument`ï¼šè¡¨ç¤ºç”¨äºç›¸ä¼¼åº¦æœç´¢çš„å‘é‡åŒ–å†…å®¹  
  - `AnalysisResult`ï¼šè¡¨ç¤ºAIåˆ†æè¾“å‡º
- **å€¼å¯¹è±¡** (`value_objects/`)ï¼šè¡¨ç¤ºä¸šåŠ¡æ¦‚å¿µçš„ä¸å¯å˜å¯¹è±¡
  - `Sentiment`ï¼šå¸¦ç½®ä¿¡åº¦çš„æƒ…æ„Ÿåˆ†æç»“æœ
  - `StockMention`ï¼šå¸¦ä¸Šä¸‹æ–‡çš„è‚¡ç¥¨ç¬¦å·æåŠ
- **ä»“å‚¨æ¥å£** (`repositories/`)ï¼šæ•°æ®è®¿é—®æŠ½è±¡
  - `NewsRepository`ï¼šæ–°é—»æ–‡ç« æ•°æ®è®¿é—®åˆçº¦
  - `VectorRepository`ï¼šå¤šåç«¯æ”¯æŒçš„å‘é‡å­˜å‚¨æŠ½è±¡
  - `AnalysisRepository`ï¼šåˆ†æç»“æœæ•°æ®ç®¡ç†

**å…³é”®åŸåˆ™**:
- ä¸ä¾èµ–å¤–éƒ¨æ¡†æ¶
- å…·æœ‰ä¸šåŠ¡è¡Œä¸ºçš„ä¸°å¯Œé¢†åŸŸå¯¹è±¡
- æ•°æ®å®Œæ•´æ€§çš„ä¸å¯å˜å€¼å¯¹è±¡
- åŸºç¡€è®¾æ–½ç‹¬ç«‹çš„æŠ½è±¡æ¥å£

#### ğŸ’¼ åº”ç”¨å±‚ (`src/application/`)
**ç›®çš„**ï¼šç¼–æ’ä¸šåŠ¡å·¥ä½œæµå¹¶åè°ƒå„å±‚ä¹‹é—´çš„äº¤äº’

**ç»„ä»¶**:
- **ç”¨ä¾‹** (`use_cases/`)ï¼šä¸šåŠ¡å·¥ä½œæµå®ç°
  - `TestVectorStorageUseCase`ï¼šå‘é‡å­˜å‚¨åŠŸèƒ½æµ‹è¯•
  - æœªæ¥ï¼š`NewsProcessingUseCase`ã€`ReportGenerationUseCase`
- **æœåŠ¡** (`services/`)ï¼šåº”ç”¨ç‰¹å®šçš„ä¸šåŠ¡é€»è¾‘
- **DTOs** (`dtos/`)ï¼šè·¨å±‚é€šä¿¡çš„æ•°æ®ä¼ è¾“å¯¹è±¡

**å…³é”®åŸåˆ™**:
- ç¼–æ’é¢†åŸŸå¯¹è±¡ä»¥å®ç°ä¸šåŠ¡ç”¨ä¾‹
- ç®¡ç†äº‹åŠ¡å¹¶åè°ƒä»“å‚¨ä¹‹é—´çš„æ“ä½œ
- åœ¨è¡¨ç°å±‚å’Œé¢†åŸŸå±‚ä¹‹é—´è½¬æ¢æ•°æ®
- ä¸åŒ…å«ä¸šåŠ¡è§„åˆ™ï¼ˆå§”æ‰˜ç»™é¢†åŸŸå±‚ï¼‰

#### âš¡ åŸºç¡€è®¾æ–½å±‚ (`src/infrastructure/`)
**ç›®çš„**ï¼šå®ç°æŠ€æœ¯å…³æ³¨ç‚¹å’Œå¤–éƒ¨é›†æˆ

**ç»„ä»¶**:
- **æ•°æ®åº“** (`database/`)ï¼š
  - `models.py`ï¼šSQLAlchemy ORMæ¨¡å‹
  - `connection.py`ï¼šæ•°æ®åº“è¿æ¥ç®¡ç†
  - `repositories/`ï¼šå…·ä½“ä»“å‚¨å®ç°
- **å¤–éƒ¨æœåŠ¡** (`external/`)ï¼š
  - `openai/`ï¼šAIåˆ†ææœåŠ¡é›†æˆ
  - `data_sources/`ï¼šæ–°é—»å’Œå¸‚åœºæ•°æ®è·å–å™¨
  - `notifications/`ï¼šSlackå’ŒæŠ¥å‘ŠæŠ•é€’
- **é…ç½®** (`config/`)ï¼š
  - `vector_storage_factory.py`ï¼šå¯æ’æ‹”å‘é‡å­˜å‚¨åç«¯
  - `settings.py`ï¼šåº”ç”¨é…ç½®ç®¡ç†

**å…³é”®åŸåˆ™**:
- å®ç°é¢†åŸŸä»“å‚¨æ¥å£
- ç®¡ç†å¤–éƒ¨æœåŠ¡é›†æˆ
- å¤„ç†åŸºç¡€è®¾æ–½å…³æ³¨ç‚¹ï¼ˆæ•°æ®åº“ã€APIã€æ–‡ä»¶ç³»ç»Ÿï¼‰
- æä¾›é…ç½®å’Œä¾èµ–æ³¨å…¥

#### ğŸ¨ è¡¨ç°å±‚ (`src/presentation/`)
**ç›®çš„**ï¼šå¤„ç†HTTPé€šä¿¡å’ŒAPIå¥‘çº¦

**ç»„ä»¶**:
- **API** (`api/`)ï¼šFastAPIè·¯ç”±å¤„ç†å™¨
- **æ¨¡å¼** (`schemas/`)ï¼šè¯·æ±‚/å“åº”éªŒè¯æ¨¡å‹
- **ä¸­é—´ä»¶** (`middleware/`)ï¼šæ¨ªåˆ‡å…³æ³¨ç‚¹ï¼ˆè®¤è¯ã€æ—¥å¿—ã€CORSï¼‰

**å…³é”®åŸåˆ™**:
- å°†HTTPè¯·æ±‚è½¬æ¢ä¸ºåº”ç”¨ç”¨ä¾‹
- éªŒè¯è¾“å…¥å¹¶æ ¼å¼åŒ–è¾“å‡º
- å¤„ç†HTTPç‰¹å®šå…³æ³¨ç‚¹ï¼ˆçŠ¶æ€ç ã€å¤´éƒ¨ï¼‰
- ç»´æŠ¤APIå¥‘çº¦å’Œç‰ˆæœ¬æ§åˆ¶

---

## ğŸ“Š æ•°æ®æ¨¡å‹

### é¢†åŸŸæ•°æ®æ¨¡å‹

é¢†åŸŸå±‚å®šä¹‰äº†æ•è·æŠ•èµ„ç ”ç©¶é¢†åŸŸåŸºæœ¬æ¦‚å¿µçš„çº¯ä¸šåŠ¡å¯¹è±¡ã€‚

```mermaid
erDiagram
    NewsArticle ||--o{ AnalysisResult : "æ‹¥æœ‰å¤šä¸ª"
    NewsArticle ||--o{ VectorDocument : "ç”Ÿæˆ"
    AnalysisResult ||--o{ VectorDocument : "å¯ä»¥è¢«å‘é‡åŒ–"
    
    NewsArticle {
        int id PK
        string url UK
        string title
        text content
        string content_hash UK
        string source
        string author
        datetime published_at
        datetime fetched_at
        json metadata
        enum processing_status
        int processing_attempts
        datetime last_processed_at
        datetime created_at
        datetime updated_at
    }
    
    VectorDocument {
        int id PK
        enum source_type
        int source_id FK
        string content_hash UK
        vector_1536 embedding
        string embedding_model
        int dimension
        float norm
        json metadata
        enum data_tier
        datetime last_accessed_at
        string external_vector_id
        datetime created_at
    }
    
    AnalysisResult {
        int id PK
        int article_id FK
        enum analysis_type
        string model_name
        string model_version
        json result
        float confidence_score
        int processing_time_ms
        int tokens_used
        decimal cost_estimate
        datetime created_at
    }
```

#### ğŸ“° NewsArticle å®ä½“

**ç›®çš„**ï¼šè¡¨ç¤ºå…·æœ‰å¤„ç†ç”Ÿå‘½å‘¨æœŸç®¡ç†çš„é‡‘èæ–°é—»æ–‡ç« 

**å…³é”®å±æ€§**:
```python
@dataclass
class NewsArticle:
    # æ ¸å¿ƒå†…å®¹
    url: str                           # å”¯ä¸€æ–‡ç« URL
    title: str                         # æ–‡ç« æ ‡é¢˜
    content: str                       # å®Œæ•´æ–‡ç« æ–‡æœ¬
    content_hash: str                  # ç”¨äºå»é‡çš„SHA-256
    source: str                        # æ–°é—»æä¾›å•†ï¼ˆè·¯é€ç¤¾ã€å½­åšç¤¾ç­‰ï¼‰
    
    # å‘å¸ƒä¿¡æ¯  
    author: Optional[str]              # æ–‡ç« ä½œè€…
    published_at: Optional[datetime]   # åŸå§‹å‘å¸ƒæ—¶é—´
    fetched_at: Optional[datetime]     # æˆ‘ä»¬è·å–çš„æ—¶é—´
    
    # å¤„ç†ç”Ÿå‘½å‘¨æœŸ
    processing_status: ProcessingStatus # pending/processing/completed/failed
    processing_attempts: int            # é‡è¯•è®¡æ•°å™¨
    last_processed_at: Optional[datetime] # æœ€åå¤„ç†å°è¯•æ—¶é—´
    
    # çµæ´»æ•°æ®
    metadata: Dict[str, Any]           # é¢å¤–ç»“æ„åŒ–æ•°æ®
```

**ä¸šåŠ¡è¡Œä¸º**:
- `mark_processing_started()`ï¼šè·Ÿè¸ªå¤„ç†å°è¯•
- `mark_processing_completed()`ï¼šæˆåŠŸæ—¶æ›´æ–°çŠ¶æ€
- `should_retry_processing()`ï¼šç¡®å®šé‡è¯•èµ„æ ¼
- `get_content_snippet()`ï¼šè¿”å›æˆªæ–­çš„å†…å®¹é¢„è§ˆ

#### ğŸ¯ VectorDocument å®ä½“

**ç›®çš„**ï¼šè¡¨ç¤ºè½¬æ¢ä¸ºå‘é‡åµŒå…¥ä»¥è¿›è¡Œè¯­ä¹‰æœç´¢çš„å†…å®¹

**å…³é”®å±æ€§**:
```python  
@dataclass
class VectorDocument:
    # å‘é‡æ ¸å¿ƒ
    source_type: VectorSourceType      # news_article/analysis_result/market_data
    source_id: int                     # å¼•ç”¨æºå®ä½“
    content_hash: str                  # é“¾æ¥åˆ°åŸå§‹å†…å®¹
    embedding: List[float]             # 1536ç»´OpenAIåµŒå…¥
    embedding_model: str               # "text-embedding-ada-002"
    
    # å‘é‡å±æ€§
    dimension: Optional[int]           # åµŒå…¥ç»´åº¦ï¼ˆ1536ï¼‰
    norm: Optional[float]              # æ€§èƒ½ç¼“å­˜çš„L2èŒƒæ•°
    
    # æ•°æ®ç”Ÿå‘½å‘¨æœŸï¼ˆç¬¬äºŒé˜¶æ®µå‡†å¤‡ï¼‰
    data_tier: DataTier                # hot/warm/coldå­˜å‚¨ç­–ç•¥
    last_accessed_at: Optional[datetime] # ç”¨äºå±‚çº§è¿ç§»å†³ç­–
    external_vector_id: Optional[str]   # æ··åˆå­˜å‚¨çš„Qdrant/Pinecone ID
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any]           # æºä¸Šä¸‹æ–‡å’Œå±æ€§
```

**ä¸šåŠ¡è¡Œä¸º**:
- `cosine_similarity()`ï¼šè®¡ç®—ä¸å…¶ä»–å‘é‡çš„ç›¸ä¼¼åº¦
- `normalize_vector()`ï¼šè¿”å›å•ä½å‘é‡
- `should_migrate_to_cold()`ï¼šç¡®å®šå­˜å‚¨å±‚çº§è¿ç§»
- `update_access_time()`ï¼šè·Ÿè¸ªç”Ÿå‘½å‘¨æœŸç®¡ç†çš„ä½¿ç”¨æƒ…å†µ

#### ğŸ“ˆ AnalysisResult å®ä½“

**ç›®çš„**ï¼šå­˜å‚¨å¸¦æœ‰æ€§èƒ½æŒ‡æ ‡çš„AIé©±åŠ¨åˆ†æè¾“å‡º

**å…³é”®å±æ€§**:
```python
@dataclass  
class AnalysisResult:
    # åˆ†ææ ¸å¿ƒ
    article_id: int                    # æºæ–‡ç« å¼•ç”¨
    analysis_type: AnalysisType        # topic_extraction/sentiment/stock_mention/ç­‰
    model_name: str                    # "gpt-4o-mini"
    result: Dict[str, Any]             # çµæ´»çš„åˆ†æè¾“å‡ºç»“æ„
    
    # æ¨¡å‹æ€§èƒ½
    confidence_score: Optional[float]  # æ¨¡å‹ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰
    processing_time_ms: Optional[int]  # æ‰§è¡ŒæŒç»­æ—¶é—´
    tokens_used: Optional[int]         # OpenAIä»¤ç‰Œæ¶ˆè´¹
    cost_estimate: Optional[float]     # ä¼°è®¡APIæˆæœ¬
    
    # ç‰ˆæœ¬æ§åˆ¶  
    model_version: Optional[str]       # å¯é‡ç°æ€§çš„æ¨¡å‹ç‰ˆæœ¬
```

**ä¸šåŠ¡è¡Œä¸º**:
- `topics`ï¼šä»åˆ†æç»“æœä¸­æå–ä¸»é¢˜åˆ—è¡¨
- `sentiment`ï¼šè·å–æƒ…æ„Ÿåˆ†ç±»
- `stocks_mentioned`ï¼šè¿”å›æåŠçš„è‚¡ç¥¨ç¬¦å·
- `is_high_confidence()`ï¼šæ£€æŸ¥åˆ†ææ˜¯å¦è¾¾åˆ°è´¨é‡é˜ˆå€¼

### åŸºç¡€è®¾æ–½æ•°æ®æ¨¡å‹

åŸºç¡€è®¾æ–½å±‚å°†è¿™äº›é¢†åŸŸæ¦‚å¿µå®ç°ä¸ºå¸¦æœ‰æ€§èƒ½ä¼˜åŒ–çš„PostgreSQLè¡¨ã€‚

#### ğŸ—ƒï¸ æ•°æ®åº“æ¨¡å¼è®¾è®¡

```mermaid
graph TB
    subgraph "æ ¸å¿ƒè¡¨"
        T1[news_articles<br/>ğŸ“° æ–°é—»å†…å®¹]
        T2[analysis_results<br/>ğŸ¤– AIåˆ†æ] 
        T3[vector_embeddings<br/>ğŸ¯ è¯­ä¹‰å‘é‡]
    end
    
    subgraph "æ”¯æŒè¡¨"
        T4[stocks<br/>ğŸ“Š è‚¡ç¥¨ä¸»æ•°æ®]
        T5[stock_prices<br/>ğŸ’¹ ä»·æ ¼å†å²]
        T6[reports<br/>ğŸ“‘ ç”Ÿæˆçš„æŠ¥å‘Š]
        T7[system_configurations<br/>âš™ï¸ åº”ç”¨è®¾ç½®]
        T8[task_executions<br/>ğŸ“‹ ä½œä¸šå†å²]
        T9[vector_sync_status<br/>ğŸ”„ ç¬¬äºŒé˜¶æ®µåŒæ­¥]
    end
    
    T1 --> T2
    T1 --> T3
    T2 --> T3
    T4 --> T5
    T3 --> T9
    
    classDef core fill:#e8f5e8,stroke:#2e7d32
    classDef support fill:#e3f2fd,stroke:#1565c0
    
    class T1,T2,T3 core
    class T4,T5,T6,T7,T8,T9 support
```

#### ğŸ“‹ è¡¨è§„æ ¼è¯´æ˜

**news_articles** - æ ¸å¿ƒæ–°é—»å†…å®¹å­˜å‚¨
```sql
CREATE TABLE news_articles (
    id                    BIGSERIAL PRIMARY KEY,
    url                   VARCHAR(1000) UNIQUE NOT NULL,
    title                 VARCHAR(500) NOT NULL,  
    content               TEXT,
    content_hash          VARCHAR(64) UNIQUE NOT NULL,
    source                VARCHAR(100) NOT NULL,
    author                VARCHAR(200),
    published_at          TIMESTAMP,
    fetched_at            TIMESTAMP DEFAULT NOW(),
    article_metadata      JSONB DEFAULT '{}',
    processing_status     VARCHAR(20) DEFAULT 'pending',
    processing_attempts   INTEGER DEFAULT 0,
    last_processed_at     TIMESTAMP,
    created_at            TIMESTAMP DEFAULT NOW(),
    updated_at            TIMESTAMP DEFAULT NOW()
);

-- æ€§èƒ½ç´¢å¼•
CREATE INDEX idx_news_published_at ON news_articles(published_at);
CREATE INDEX idx_news_source_published ON news_articles(source, published_at);  
CREATE INDEX idx_news_metadata_gin ON news_articles USING gin(article_metadata);
```

**vector_embeddings** - ä½¿ç”¨pgvectorçš„é«˜æ€§èƒ½å‘é‡å­˜å‚¨
```sql
CREATE TABLE vector_embeddings (
    id                    BIGSERIAL PRIMARY KEY,
    source_type           VARCHAR(50) NOT NULL,      -- 'news_article', 'analysis_result'
    source_id             BIGINT NOT NULL,           -- å¼•ç”¨æºå®ä½“
    content_hash          VARCHAR(64) NOT NULL,
    embedding             VECTOR(1536),              -- OpenAIåµŒå…¥ç»´åº¦
    embedding_model       VARCHAR(100) DEFAULT 'text-embedding-ada-002',
    dimension             INTEGER NOT NULL DEFAULT 1536,
    norm                  DECIMAL(10,6),             -- ç¼“å­˜çš„L2èŒƒæ•°
    vector_metadata       JSONB DEFAULT '{}',
    data_tier             VARCHAR(10) DEFAULT 'hot', -- 'hot'/'warm'/'cold'
    last_accessed_at      TIMESTAMP DEFAULT NOW(),
    external_vector_id    VARCHAR(100),              -- ç¬¬äºŒé˜¶æ®µï¼šQdrant/Pinecone ID
    created_at            TIMESTAMP DEFAULT NOW()
);

-- å‘é‡ç›¸ä¼¼åº¦æœç´¢ä¼˜åŒ–  
CREATE INDEX idx_vector_embedding_hnsw ON vector_embeddings 
USING hnsw (embedding vector_cosine_ops) 
WITH (m = 16, ef_construction = 64);

-- è¿‡æ»¤çš„å¤åˆç´¢å¼•
CREATE INDEX idx_vector_source ON vector_embeddings(source_type, source_id);
CREATE UNIQUE INDEX idx_vector_unique ON vector_embeddings(content_hash, embedding_model);
```

**analysis_results** - å¸¦æ€§èƒ½è·Ÿè¸ªçš„AIåˆ†æè¾“å‡º
```sql
CREATE TABLE analysis_results (
    id                    BIGSERIAL PRIMARY KEY,
    article_id            BIGINT NOT NULL REFERENCES news_articles(id) ON DELETE CASCADE,
    analysis_type         VARCHAR(50) NOT NULL,      -- 'topic_extraction', 'sentiment', ç­‰
    model_name            VARCHAR(100) NOT NULL,     -- 'gpt-4o-mini'
    model_version         VARCHAR(50),
    result                JSONB NOT NULL,            -- çµæ´»çš„åˆ†æè¾“å‡º
    processing_time_ms    INTEGER,
    tokens_used           INTEGER,
    cost_estimate         DECIMAL(10,6),
    confidence_score      DECIMAL(3,2),              -- 0.00 to 1.00
    created_at            TIMESTAMP DEFAULT NOW()
);

-- æŸ¥è¯¢ä¼˜åŒ–ç´¢å¼•
CREATE INDEX idx_analysis_article_type ON analysis_results(article_id, analysis_type);
CREATE INDEX idx_analysis_model_created ON analysis_results(model_name, created_at);
CREATE INDEX idx_analysis_result_gin ON analysis_results USING gin(result);
```

#### ğŸ”„ æ•°æ®æµè½¬å’Œè½¬æ¢

```mermaid
sequenceDiagram
    participant API as FastAPI
    participant UC as ç”¨ä¾‹
    participant DE as é¢†åŸŸå®ä½“  
    participant REPO as ä»“å‚¨
    participant DB as PostgreSQL
    
    API->>UC: å¸¦DTOçš„è¯·æ±‚
    UC->>DE: åˆ›å»º/æ›´æ–°é¢†åŸŸå®ä½“
    DE->>DE: éªŒè¯ä¸šåŠ¡è§„åˆ™
    UC->>REPO: é€šè¿‡ä»“å‚¨æ¥å£ä¿å­˜
    REPO->>REPO: å®ä½“è½¬æ¢ä¸ºDBæ¨¡å‹
    REPO->>DB: æ‰§è¡ŒSQL
    DB-->>REPO: è¿”å›DBæ¨¡å‹
    REPO->>REPO: DBæ¨¡å‹è½¬æ¢ä¸ºå®ä½“
    REPO-->>UC: è¿”å›é¢†åŸŸå®ä½“
    UC-->>API: è¿”å›DTO
```

**è½¬æ¢å±‚çº§**:
1. **APIæ¨¡å¼ â†” DTO**ï¼šè¾“å…¥éªŒè¯å’Œè¾“å‡ºæ ¼å¼åŒ–
2. **DTO â†” é¢†åŸŸå®ä½“**ï¼šåº”ç”¨å±‚åè°ƒ  
3. **é¢†åŸŸå®ä½“ â†” æ•°æ®åº“æ¨¡å‹**ï¼šåŸºç¡€è®¾æ–½æŒä¹…åŒ–
4. **æ•°æ®åº“æ¨¡å‹ â†” å‘é‡å­˜å‚¨**ï¼šä¸“é—¨çš„å‘é‡æ“ä½œ

---

## ğŸ¯ æ ¸å¿ƒæ¶æ„æ¨¡å¼

### ä»“å‚¨æ¨¡å¼

**ç›®çš„**ï¼šé¢†åŸŸé€»è¾‘å’Œæ•°æ®æŒä¹…åŒ–ä¹‹é—´çš„æŠ½è±¡å±‚

**å®ç°**:
```python
# é¢†åŸŸæ¥å£ (src/domain/repositories/vector_repository.py)
class VectorRepository(ABC):
    @abstractmethod
    async def similarity_search(
        self, 
        query_vector: List[float], 
        top_k: int = 10
    ) -> List[SearchResult]:
        pass

# åŸºç¡€è®¾æ–½å®ç° (src/infrastructure/database/repositories/)
class PostgreSQLVectorRepository(VectorRepository):
    async def similarity_search(self, query_vector: List[float], top_k: int) -> List[SearchResult]:
        # PostgreSQL + pgvector å®ç°
        stmt = (
            select(VectorEmbedding, VectorEmbedding.embedding.cosine_distance(query_vector))
            .order_by(VectorEmbedding.embedding.cosine_distance(query_vector))
            .limit(top_k)
        )
        # ... å®ç°ç»†èŠ‚
```

**ä¼˜åŠ¿**:
- é¢†åŸŸå±‚ä¿æŒç‹¬ç«‹äºæ•°æ®å­˜å‚¨æŠ€æœ¯
- ç¬¬äºŒé˜¶æ®µå¯è½»æ¾åœ¨PostgreSQLå’ŒQdrantä¹‹é—´åˆ‡æ¢
- ä½¿ç”¨æ¨¡æ‹Ÿä»“å‚¨ç®€åŒ–å•å…ƒæµ‹è¯•
- ä¸šåŠ¡é€»è¾‘ä¸æŒä¹…åŒ–å…³æ³¨ç‚¹çš„æ¸…æ™°åˆ†ç¦»

### å·¥å‚æ¨¡å¼

**ç›®çš„**ï¼šå‘é‡å­˜å‚¨åç«¯çš„å¯æ’æ‹”æ¶æ„

**å®ç°**:
```python
# å·¥å‚ (src/infrastructure/config/vector_storage_factory.py)
class VectorStorageFactory:
    def create_repository(self) -> VectorRepository:
        provider = os.getenv("VECTOR_STORAGE_PROVIDER", "postgresql")
        
        if provider == "postgresql":
            return PostgreSQLVectorRepository()
        elif provider == "qdrant":  # ç¬¬äºŒé˜¶æ®µ
            return QdrantVectorRepository()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")

# åœ¨åº”ç”¨å±‚ä¸­çš„ä½¿ç”¨
vector_storage_factory = VectorStorageFactory()
repository = vector_storage_factory.create_repository()
```

**ä¼˜åŠ¿**:
- åŸºäºç¯å¢ƒçš„åç«¯åˆ‡æ¢
- è¿ç§»å­˜å‚¨åç«¯æ—¶æ— éœ€ä»£ç æ›´æ”¹
- ä¸åŒå‘é‡æ•°æ®åº“ä¹‹é—´çš„ä¸€è‡´æ¥å£
- æ˜“äºæ·»åŠ æ–°çš„å‘é‡å­˜å‚¨æä¾›å•†

### é¢†åŸŸé©±åŠ¨è®¾è®¡èšåˆ

**ç›®çš„**ï¼šä¸€è‡´æ€§è¾¹ç•Œå’Œäº‹åŠ¡å®Œæ•´æ€§

**è®¾è®¡**:
```python
# NewsArticle ä½œä¸ºèšåˆæ ¹
class NewsArticle:
    def process_with_ai(self, analyzer: AIAnalyzer) -> AnalysisResult:
        """ç»´æŒä¸€è‡´æ€§çš„ä¸šåŠ¡æ“ä½œ"""
        if not self.is_ready_for_processing():
            raise DomainException("æ–‡ç« å°šæœªå‡†å¤‡å¥½å¤„ç†")
        
        self.mark_processing_started()
        result = analyzer.analyze(self.content)
        self.mark_processing_completed()
        
        return result

# VectorDocument ä½œä¸ºç‹¬ç«‹èšåˆ  
class VectorDocument:
    def calculate_similarity(self, other: 'VectorDocument') -> float:
        """å¸¦ä¸šåŠ¡é€»è¾‘çš„é¢†åŸŸæ“ä½œ"""
        if self.dimension != other.dimension:
            raise DomainException("ç»´åº¦ä¸åŒ¹é…")
        
        return self.cosine_similarity(other.embedding)
```

### CQRSå‡†å¤‡ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰

**å½“å‰çŠ¶æ€**ï¼šç®€å•ä»“å‚¨æ¨¡å¼
**ç¬¬äºŒé˜¶æ®µç›®æ ‡**ï¼šå‘½ä»¤æŸ¥è¯¢èŒè´£åˆ†ç¦»

```mermaid
graph LR
    subgraph "ç¬¬ä¸€é˜¶æ®µï¼šç®€å•CRUD"
        R1[ä»“å‚¨æ¥å£]
        R2[å•ä¸€å®ç°]
    end
    
    subgraph "ç¬¬äºŒé˜¶æ®µï¼šCQRS"
        C1[å‘½ä»¤ç«¯<br/>å†™æ“ä½œ]
        Q1[æŸ¥è¯¢ç«¯<br/>è¯»æ“ä½œ] 
        C2[PostgreSQL<br/>äº‹åŠ¡æ€§]
        Q2[Qdrant<br/>å‘é‡æœç´¢]
    end
    
    R1 --> C1
    R1 --> Q1
    C1 --> C2
    Q1 --> Q2
    
    classDef current fill:#e8f5e8,stroke:#2e7d32
    classDef future fill:#e3f2fd,stroke:#1565c0
    
    class R1,R2 current
    class C1,Q1,C2,Q2 future
```

---

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

### æ ¸å¿ƒæŠ€æœ¯

| å±‚çº§ | æŠ€æœ¯ | ç”¨é€” | ç‰ˆæœ¬ |
|-------|------------|---------|---------|
| **API** | FastAPI | å¼‚æ­¥webæ¡†æ¶ | â‰¥0.104.0 |
| **ORM** | SQLAlchemy | å¸¦å¼‚æ­¥æ”¯æŒçš„æ•°æ®åº“ORM | â‰¥2.0.0 |
| **æ•°æ®åº“** | PostgreSQL | ä¸»è¦æ•°æ®å­˜å‚¨ | â‰¥15.0 |
| **å‘é‡** | pgvector | å‘é‡ç›¸ä¼¼åº¦æœç´¢ | â‰¥0.2.0 |
| **AI** | OpenAI | åˆ†æè¯­è¨€æ¨¡å‹ | â‰¥1.86.0 |
| **ç¼–æ’** | LangChain | LLMå·¥ä½œæµç®¡ç† | â‰¥0.3.17 |

### å¼€å‘ä¸è¿ç»´

| ç±»åˆ« | æŠ€æœ¯ | ç”¨é€” |
|----------|------------|---------|
| **æµ‹è¯•** | pytest | å•å…ƒå’Œé›†æˆæµ‹è¯• |
| **ç±»å‹æ£€æŸ¥** | mypy | é™æ€ç±»å‹éªŒè¯ |
| **å®¹å™¨åŒ–** | Docker | å¼€å‘å’Œéƒ¨ç½² |
| **ç¯å¢ƒ** | python-dotenv | é…ç½®ç®¡ç† |
| **æ—¥å¿—** | structlog | ç»“æ„åŒ–åº”ç”¨æ—¥å¿— |
| **ç›‘æ§** | è‡ªå®šä¹‰å¥åº·æ£€æŸ¥ | ç³»ç»Ÿå¥åº·ç›‘æ§ |

### å¤–éƒ¨é›†æˆ

```mermaid
graph TB
    subgraph "AIæœåŠ¡"
        AI1[OpenAI GPT-4o-mini]
        AI2[OpenAI text-embedding-ada-002]
        AI3[LangChainå·¥ä½œæµ]
    end
    
    subgraph "æ•°æ®æº"
        DS1[æ–°é—»APIæº]
        DS2[é‡‘èæ•°æ®API]
        DS3[å¸‚åœºæ•°æ®æä¾›å•†]
    end
    
    subgraph "é€šçŸ¥"
        N1[Slack Webhooks]
        N2[é‚®ä»¶æœåŠ¡]
        N3[æŠ¥å‘Šç”Ÿæˆ]
    end
    
    subgraph "AIæŠ•èµ„å¹³å°"
        P[æ ¸å¿ƒåº”ç”¨]
    end
    
    AI1 --> P
    AI2 --> P  
    AI3 --> P
    DS1 --> P
    DS2 --> P
    DS3 --> P
    P --> N1
    P --> N2
    P --> N3
    
    classDef ai fill:#f3e5f5,stroke:#7b1fa2
    classDef data fill:#e8f5e8,stroke:#2e7d32  
    classDef notification fill:#fff3e0,stroke:#f57c00
    classDef platform fill:#e3f2fd,stroke:#1565c0
    
    class AI1,AI2,AI3 ai
    class DS1,DS2,DS3 data
    class N1,N2,N3 notification
    class P platform
```

### æ€§èƒ½ç‰¹å¾

| ç»„ä»¶ | æ€§èƒ½ç›®æ ‡ | æµ‹é‡æ–¹å¼ |
|-----------|-------------------|-------------|
| **å‘é‡æœç´¢** | < 50msè·å–å‰10ä¸ªç»“æœ | pgvector HNSWç´¢å¼• |
| **AIåˆ†æ** | < 5sæ¯ç¯‡æ–‡ç«  | OpenAI APIå»¶è¿Ÿ |
| **æ•°æ®åº“æŸ¥è¯¢** | < 100mså¤æ‚è¿æ¥ | PostgreSQLä¼˜åŒ– |
| **APIå“åº”** | < 200msæ ‡å‡†è¯·æ±‚ | FastAPIå¼‚æ­¥æ€§èƒ½ |
| **å†…å­˜ä½¿ç”¨** | < 2GBæ ‡å‡†å·¥ä½œè´Ÿè½½ | Pythonå†…å­˜ç®¡ç† |

---

## ğŸ¤” æ¶æ„å†³ç­–è®°å½•

### ADR-001ï¼šPostgreSQL + pgvector è€Œéä¸“ç”¨å‘é‡æ•°æ®åº“

**çŠ¶æ€**ï¼šå·²æ¥å— âœ…

**èƒŒæ™¯**ï¼š 
éœ€è¦å‘é‡ç›¸ä¼¼åº¦æœç´¢åŠŸèƒ½è¿›è¡Œé‡‘èæ–°é—»çš„è¯­ä¹‰åˆ†æã€‚

**å†³ç­–**ï¼š 
ä½¿ç”¨å¸¦pgvectoræ‰©å±•çš„PostgreSQLï¼Œè€Œéä¸“ç”¨å‘é‡æ•°æ®åº“ï¼ˆPineconeã€Weaviateã€Qdrantï¼‰ã€‚

**ç†ç”±**:
- **è¿ç»´ç®€å•æ€§**ï¼šç®¡ç†å•ä¸€æ•°æ®åº“è€Œéå¤šä¸ªç³»ç»Ÿ
- **ACIDåˆè§„**ï¼šå…³ç³»å‹å’Œå‘é‡æ•°æ®é—´çš„äº‹åŠ¡ä¸€è‡´æ€§
- **æˆæœ¬æ•ˆç›Š**ï¼šå‘é‡æ“ä½œæ— éœ€é¢å¤–åŸºç¡€è®¾æ–½æˆ–APIæˆæœ¬
- **æ€§èƒ½å……åˆ†**ï¼špgvector HNSWç´¢å¼•åœ¨æˆ‘ä»¬çš„è§„æ¨¡ä¸‹æä¾›è¶³å¤Ÿæ€§èƒ½
- **ç”Ÿæ€é›†æˆ**ï¼šä¸ç°æœ‰SQLAlchemy ORMæ— ç¼é›†æˆ

**åæœ**:
- âœ… é™ä½è¿ç»´å¤æ‚æ€§
- âœ… æ›´ä½çš„åŸºç¡€è®¾æ–½æˆæœ¬  
- âœ… ä¸€è‡´çš„å¤‡ä»½å’Œæ¢å¤ç¨‹åº
- âŒ åœ¨å¤§è§„æ¨¡ï¼ˆ>1000ä¸‡å‘é‡ï¼‰æ—¶æ½œåœ¨æ€§èƒ½é™åˆ¶
- âŒ è¾ƒå°‘çš„ä¸“é—¨å‘é‡æ“ä½œåŠŸèƒ½

**ç¬¬äºŒé˜¶æ®µè¿ç§»è·¯å¾„**ï¼š 
æ··åˆæ–¹æ³•ï¼ŒPostgreSQLç”¨äºå…ƒæ•°æ®ï¼ŒQdrantç”¨äºå‘é‡æ“ä½œã€‚

### ADR-002ï¼šé¢†åŸŸé©±åŠ¨è®¾è®¡æ¶æ„

**çŠ¶æ€**ï¼šå·²æ¥å— âœ…

**èƒŒæ™¯**ï¼š 
éšç€ä¸šåŠ¡å¤æ‚æ€§å¢é•¿ï¼Œä¹‹å‰çš„å•ä½“æ¶æ„å˜å¾—éš¾ä»¥ç»´æŠ¤å’Œæµ‹è¯•ã€‚

**å†³ç­–**ï¼š 
å®ç°éµå¾ªé¢†åŸŸé©±åŠ¨è®¾è®¡åŸåˆ™çš„åˆ†å±‚æ¶æ„ã€‚

**ç†ç”±**:
- **ä¸šåŠ¡ä¸“æ³¨**ï¼šé¢†åŸŸå±‚æ•è·å¤æ‚çš„é‡‘èåˆ†æè§„åˆ™
- **å¯æµ‹è¯•æ€§**ï¼šæ¸…æ™°åˆ†ç¦»æ”¯æŒéš”ç¦»å•å…ƒæµ‹è¯•
- **å¯ç»´æŠ¤æ€§**ï¼šæ¯å±‚éƒ½æœ‰å•ä¸€èŒè´£
- **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ–°çš„åˆ†æç±»å‹å’Œæ•°æ®æº
- **å›¢é˜Ÿåä½œ**ï¼šä¸åŒå¼€å‘è§’è‰²çš„æ¸…æ™°è¾¹ç•Œ

**åæœ**:
- âœ… æ”¹å–„ä»£ç ç»„ç»‡å’Œå¯ç»´æŠ¤æ€§
- âœ… æ›´å¥½çš„ä¸šåŠ¡å’ŒæŠ€æœ¯å…³æ³¨ç‚¹åˆ†ç¦»
- âœ… å¢å¼ºå¯æµ‹è¯•æ€§å’Œå¼€å‘é€Ÿåº¦
- âŒ å¢åŠ åˆå§‹å¼€å‘å¤æ‚æ€§
- âŒ å¯¹ä¸ç†Ÿæ‚‰DDDçš„å¼€å‘äººå‘˜æœ‰å­¦ä¹ æ›²çº¿

### ADR-003ï¼šå¼‚æ­¥ä¼˜å…ˆæ¶æ„

**çŠ¶æ€**ï¼šå·²æ¥å— âœ…

**èƒŒæ™¯**ï¼š 
éœ€è¦é«˜æ•ˆå¤„ç†å¤šä¸ªå¹¶å‘AI APIè°ƒç”¨å’Œæ•°æ®åº“æ“ä½œã€‚

**å†³ç­–**ï¼š 
åœ¨æ•´ä¸ªåº”ç”¨æ ˆä¸­ä½¿ç”¨async/awaitï¼ˆFastAPIã€SQLAlchemy asyncã€asyncioï¼‰ã€‚

**ç†ç”±**:
- **I/Oå¯†é›†å‹å·¥ä½œè´Ÿè½½**ï¼šå¤§å¤šæ•°æ“ä½œæ¶‰åŠç½‘ç»œè°ƒç”¨ï¼ˆOpenAI APIã€æ•°æ®åº“ï¼‰
- **å¹¶å‘æ€§**ï¼šåŒæ—¶å¤„ç†å¤šç¯‡æ–°é—»æ–‡ç« 
- **èµ„æºæ•ˆç‡**ï¼šI/Oç­‰å¾…æœŸé—´æ›´å¥½çš„CPUåˆ©ç”¨ç‡
- **å¯æ‰©å±•æ€§**ï¼šç”¨ç›¸åŒç¡¬ä»¶å¤„ç†æ›´é«˜è¯·æ±‚é‡

**åæœ**:
- âœ… æ”¹å–„ååé‡å’Œå“åº”æ€§
- âœ… æ›´å¥½çš„èµ„æºåˆ©ç”¨
- âœ… å¹¶å‘å¤„ç†çš„å¯æ‰©å±•æ¶æ„
- âŒ async/awaitæ¨¡å¼å¢åŠ ä»£ç å¤æ‚æ€§
- âŒ å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­çš„è°ƒè¯•å¤æ‚æ€§

### ADR-004ï¼šå‘é‡å­˜å‚¨çš„å·¥å‚æ¨¡å¼

**çŠ¶æ€**ï¼šå·²æ¥å— âœ…

**èƒŒæ™¯**ï¼š 
éœ€è¦åœ¨ä¸æ›´æ”¹ä»£ç çš„æƒ…å†µä¸‹åœ¨ä¸åŒå‘é‡å­˜å‚¨åç«¯ä¹‹é—´åˆ‡æ¢çš„èƒ½åŠ›ã€‚

**å†³ç­–**ï¼š 
ä¸ºå‘é‡å­˜å‚¨æä¾›å•†å®ç°åŸºäºç¯å¢ƒé…ç½®çš„å·¥å‚æ¨¡å¼ã€‚

**ç†ç”±**:
- **çµæ´»æ€§**ï¼šå‘ä¸“ç”¨å‘é‡æ•°æ®åº“çš„ç®€æ˜“è¿ç§»è·¯å¾„
- **æµ‹è¯•**ï¼šå•å…ƒæµ‹è¯•çš„ç®€å•æ¨¡æ‹Ÿ
- **ç¯å¢ƒå¯¹ç­‰**ï¼šå¼€å‘ã€æ¼”ç¤ºã€ç”Ÿäº§çš„ä¸åŒåç«¯
- **ä¾›åº”å•†ç‹¬ç«‹**ï¼šé¿å…é”å®šç‰¹å®šå‘é‡æ•°æ®åº“ä¾›åº”å•†

**åæœ**:
- âœ… ç¬¬äºŒé˜¶æ®µæ··åˆæ¶æ„çš„æ¸…æ´è¿ç§»è·¯å¾„
- âœ… ç®€åŒ–æµ‹è¯•å’Œå¼€å‘å·¥ä½œæµ  
- âœ… é…ç½®é©±åŠ¨çš„åç«¯é€‰æ‹©
- âŒ é¢å¤–çš„æŠ½è±¡å±‚å¤æ‚æ€§
- âŒ æ¥å£å¿…é¡»é€‚åº”æœ€å°å…¬åˆ†æ¯åŠŸèƒ½

---

## ğŸš€ ç¬¬äºŒé˜¶æ®µå‡†å¤‡

### æ··åˆå‘é‡å­˜å‚¨ç­–ç•¥

**å½“å‰çŠ¶æ€ï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰**:
- å¸¦pgvectorçš„å•ä¸€PostgreSQLæ•°æ®åº“
- é€šè¿‡ä»“å‚¨æ¥å£çš„æ‰€æœ‰å‘é‡æ“ä½œ
- é…ç½®é©±åŠ¨çš„åç«¯é€‰æ‹©

**æœªæ¥çŠ¶æ€ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰**:
- æ··åˆPostgreSQL + Qdrantæ¶æ„
- è¯»å†™åˆ†ç¦»çš„CQRSæ¨¡å¼
- äº‹ä»¶é©±åŠ¨åŒæ­¥

```mermaid
graph TB
    subgraph "ç¬¬äºŒé˜¶æ®µï¼šæ··åˆæ¶æ„"
        subgraph "å‘½ä»¤ç«¯ï¼ˆå†™å…¥ï¼‰"
            C1[æ–°é—»å¤„ç†]
            C2[PostgreSQLä¸»æ•°æ®åº“]
            C3[äº‹åŠ¡æ•°æ®]
        end
        
        subgraph "æŸ¥è¯¢ç«¯ï¼ˆè¯»å–ï¼‰"  
            Q1[å‘é‡æœç´¢]
            Q2[Qdranté›†ç¾¤]
            Q3[ä¼˜åŒ–å‘é‡]
        end
        
        subgraph "åŒæ­¥"
            S1[äº‹ä»¶æ€»çº¿]
            S2[å‘é‡åŒæ­¥ä½œä¸š]
            S3[ä¸€è‡´æ€§ç›‘æ§]
        end
    end
    
    C1 --> C2
    C2 --> S1
    S1 --> S2
    S2 --> Q2
    Q1 --> Q2
    
    classDef write fill:#ffebee,stroke:#c62828
    classDef read fill:#e8f5e8,stroke:#2e7d32
    classDef sync fill:#fff3e0,stroke:#f57c00
    
    class C1,C2,C3 write
    class Q1,Q2,Q3 read  
    class S1,S2,S3 sync
```

### è¿ç§»ç­–ç•¥

#### ç¬¬äºŒé˜¶æ®µ 2.1ï¼šåŒå†™å®ç°
```python
class HybridVectorRepository(VectorRepository):
    def __init__(self):
        self.postgresql_repo = PostgreSQLVectorRepository()
        self.qdrant_repo = QdrantVectorRepository()
        
    async def insert_vector(self, document: VectorDocument) -> str:
        # å†™å…¥ä¸»æ•°æ®åº“ï¼ˆPostgreSQLï¼‰
        primary_id = await self.postgresql_repo.insert_vector(document)
        
        # å¼‚æ­¥å†™å…¥æ¬¡æ•°æ®åº“ï¼ˆQdrantï¼‰  
        await self._sync_to_qdrant(document, primary_id)
        
        return primary_id
        
    async def similarity_search(self, query_vector: List[float], top_k: int) -> List[SearchResult]:
        # ä»ä¼˜åŒ–çš„å‘é‡æ•°æ®åº“è¯»å–ï¼ˆQdrantï¼‰
        return await self.qdrant_repo.similarity_search(query_vector, top_k)
```

#### ç¬¬äºŒé˜¶æ®µ 2.2ï¼šäº‹ä»¶é©±åŠ¨åŒæ­¥
```python
class VectorSyncService:
    async def handle_vector_created_event(self, event: VectorCreatedEvent):
        """å‘é‡åˆ›å»ºäº‹ä»¶çš„å¼‚æ­¥åŒæ­¥å¤„ç†å™¨"""
        try:
            await self.qdrant_client.upsert_vector(
                vector_id=event.vector_id,
                embedding=event.embedding,
                metadata=event.metadata
            )
            await self.mark_sync_completed(event.vector_id)
        except Exception as e:
            await self.handle_sync_failure(event.vector_id, str(e))
```

#### ç¬¬äºŒé˜¶æ®µ 2.3ï¼šæ¸è¿›å¼è¿ç§»
1. **å‡†å¤‡**ï¼ˆå½“å‰ï¼‰ï¼šå·¥å‚æ¨¡å¼å’ŒæŠ½è±¡æ¥å£
2. **åŒå†™**ï¼šåŒæ—¶å†™å…¥PostgreSQLå’ŒQdrant
3. **è¯»å–è¿ç§»**ï¼šé€æ¸å°†è¯»å–è½¬ç§»åˆ°Qdrant  
4. **éªŒè¯**ï¼šæ¯”è¾ƒä¸¤ä¸ªç³»ç»Ÿä¹‹é—´çš„ç»“æœ
5. **å®Œå…¨è¿ç§»**ï¼šç§»é™¤PostgreSQLå‘é‡æ“ä½œ
6. **æ¸…ç†**ï¼šç§»é™¤æ—§çš„å‘é‡åˆ—å’Œç´¢å¼•

### æœªæ¥å¢å¼º

#### é«˜çº§å‘é‡æ“ä½œ
```python
# ç¬¬äºŒé˜¶æ®µå¢å¼ºå‘é‡ä»“å‚¨æ¥å£
class AdvancedVectorRepository(VectorRepository):
    async def hybrid_search(
        self,
        query_vector: List[float],
        filters: Dict[str, Any],
        alpha: float = 0.5  # æ··åˆæœç´¢æƒé‡
    ) -> List[SearchResult]:
        """ç»“åˆå‘é‡ç›¸ä¼¼åº¦ä¸ä¼ ç»Ÿè¿‡æ»¤"""
        pass
    
    async def vector_clustering(
        self,
        vectors: List[str],
        num_clusters: int
    ) -> Dict[str, List[str]]:
        """å°†ç›¸ä¼¼å‘é‡åˆ†ç»„ä¸ºé›†ç¾¤"""
        pass
    
    async def anomaly_detection(
        self,
        baseline_vectors: List[str],
        candidate_vector: str,
        threshold: float
    ) -> bool:
        """æ£€æµ‹å‘é‡ç©ºé—´ä¸­çš„å¼‚å¸¸æ¨¡å¼"""
        pass
```

#### äº‹ä»¶é©±åŠ¨æ¶æ„
```python  
class NewsProcessingWorkflow:
    async def process_news_article(self, article: NewsArticle):
        """äº‹ä»¶é©±åŠ¨çš„æ–°é—»å¤„ç†æµæ°´çº¿"""
        # ä¸ºæ¯ä¸ªå¤„ç†æ­¥éª¤å‘å‡ºé¢†åŸŸäº‹ä»¶
        await self.event_bus.publish(ArticleFetchedEvent(article.id))
        
        analysis_result = await self.ai_analyzer.analyze(article)
        await self.event_bus.publish(ArticleAnalyzedEvent(article.id, analysis_result))
        
        vector_doc = await self.vectorizer.create_embedding(article)
        await self.event_bus.publish(VectorCreatedEvent(vector_doc.id))
        
        await self.event_bus.publish(ProcessingCompletedEvent(article.id))
```

### æ€§èƒ½å’Œå¯æ‰©å±•æ€§ç›®æ ‡

| æŒ‡æ ‡ | ç¬¬ä¸€é˜¶æ®µç°çŠ¶ | ç¬¬äºŒé˜¶æ®µç›®æ ‡ | æ‰©å±•ç­–ç•¥ |
|--------|-----------------|-----------------|------------------|
| **å‘é‡æœç´¢** | 50ms @ 10ä¸‡å‘é‡ | 10ms @ 1000ä¸‡å‘é‡ | Qdranté›†ç¾¤ + HNSWä¼˜åŒ– |
| **å¹¶å‘ç”¨æˆ·** | 10ä¸ªåŒæ—¶ç”¨æˆ· | 100+ä¸ªåŒæ—¶ç”¨æˆ· | APIæ°´å¹³æ‰©å±• |
| **æ–‡ç« å¤„ç†** | 10ç¯‡æ–‡ç« /åˆ†é’Ÿ | 1000ç¯‡æ–‡ç« /åˆ†é’Ÿ | äº‹ä»¶é©±åŠ¨æµæ°´çº¿ |
| **æ•°æ®å­˜å‚¨** | 10GBæ€»è®¡ | 1TB+æ€»è®¡ | åˆ†å±‚å­˜å‚¨ç­–ç•¥ |
| **ç³»ç»Ÿå¯ç”¨æ€§** | 99.0%æ­£å¸¸è¿è¡Œ | 99.9%æ­£å¸¸è¿è¡Œ | å¤šåŒºåŸŸéƒ¨ç½² |

---

## ğŸ“š å‚è€ƒèµ„æ–™å’Œæ‰©å±•é˜…è¯»

### é¢†åŸŸé©±åŠ¨è®¾è®¡
- Evans, Eric. ã€Šé¢†åŸŸé©±åŠ¨è®¾è®¡ï¼šè½¯ä»¶æ ¸å¿ƒå¤æ‚æ€§åº”å¯¹ä¹‹é“ã€‹
- Vernon, Vaughn. ã€Šå®ç°é¢†åŸŸé©±åŠ¨è®¾è®¡ã€‹

### å‘é‡æ•°æ®åº“å’Œç›¸ä¼¼åº¦æœç´¢  
- [pgvector æ–‡æ¡£](https://github.com/pgvector/pgvector)
- [Qdrant å‘é‡æ•°æ®åº“](https://qdrant.tech/)
- [OpenAI åµŒå…¥æŒ‡å—](https://platform.openai.com/docs/guides/embeddings)

### FastAPIå’Œå¼‚æ­¥Python
- [FastAPI æ–‡æ¡£](https://fastapi.tiangolo.com/)
- [SQLAlchemy å¼‚æ­¥æ–‡æ¡£](https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html)

### é‡‘èæ•°æ®å¤„ç†
- [é‡‘èåº”ç”¨çš„LangChain](https://langchain.com/)
- [Pythoné‡åŒ–é‡‘è](https://www.quantstart.com/)

---

*æ­¤æ¶æ„æ–‡æ¡£ä¸ä»£ç åº“ä¸€èµ·ç»´æŠ¤ï¼Œå¹¶åœ¨æ¯æ¬¡é‡å¤§æ¶æ„å†³ç­–æˆ–ç³»ç»Ÿæ¼”è¿›æ—¶æ›´æ–°ã€‚*